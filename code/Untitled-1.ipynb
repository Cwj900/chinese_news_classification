{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382688/382688 [00:49<00:00, 7661.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter  # 导入Counter类\n",
    "\n",
    "# 获取停用词\n",
    "def get_stopwords(stop_file_name):\n",
    "    with open(stop_file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "    words = [i.strip() for i in lines]\n",
    "    return words\n",
    "\n",
    "# 字符清洗\n",
    "def text_cleaning(text):\n",
    "    text_result = ''\n",
    "    for char in text:\n",
    "        if '\\u4e00' <= char <= '\\u9fa5':\n",
    "            text_result += char\n",
    "    return text_result\n",
    "\n",
    "# 数据预处理\n",
    "def co_data(dataset_path, stopwords):\n",
    "    labels = []\n",
    "    texts = []\n",
    "\n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in tqdm(lines):\n",
    "            parts = line.strip().split(\"_!_\")\n",
    "            if len(parts) < 4:  # 确保数据格式正确\n",
    "                continue\n",
    "            labels.append(parts[2])\n",
    "            cleaned_text = text_cleaning(parts[3])\n",
    "            seg = jieba.cut(cleaned_text, cut_all=False)\n",
    "            text = [char for char in seg if char not in stopwords]\n",
    "            texts.append(' '.join(text))  # 用空格连接分词结果，以便CountVectorizer处理\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "# 整理类别和索引\n",
    "def co_labeldict(labels):\n",
    "    label_freq = Counter(labels)\n",
    "    id2label = {i: label for i, label in enumerate(label_freq)}\n",
    "    label2id = {label: i for i, label in enumerate(label_freq)}\n",
    "    return id2label, label2id\n",
    "\n",
    "# 加载停用词\n",
    "stopwords = get_stopwords(r'C:\\Users\\HP\\OneDrive\\桌面\\智能信息网络实验\\chinese_news_classification\\dataset\\cn_stopwords.txt')\n",
    "\n",
    "# 数据预处理\n",
    "dataset_path = r'C:\\Users\\HP\\OneDrive\\桌面\\智能信息网络实验\\chinese_news_classification\\dataset\\dataset.txt'\n",
    "texts, labels = co_data(dataset_path, stopwords)\n",
    "\n",
    "# 创建标签索引映射\n",
    "id2label, label2id = co_labeldict(labels)\n",
    "\n",
    "# 使用CountVectorizer进行文本向量化\n",
    "vectorizer = CountVectorizer(max_features=7000)\n",
    "\n",
    "# 划分数据集\n",
    "train_texts, rest_texts, train_labels, rest_labels = train_test_split(texts, labels, test_size=0.4, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(rest_texts, rest_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# 向量化文本数据\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_val = vectorizer.transform(val_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "# 将标签转换为索引\n",
    "y_train = [label2id[label] for label in train_labels]\n",
    "y_val = [label2id[label] for label in val_labels]\n",
    "y_test = [label2id[label] for label in test_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, PassiveAggressiveClassifier, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MachineLearningEnsemble(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        # 初始化机器学习模型\n",
    "        self.models = {\n",
    "            'sgd': SGDClassifier(),\n",
    "            'pa': PassiveAggressiveClassifier(),\n",
    "            'svc': LinearSVC(),\n",
    "            'ridge': RidgeClassifier(),\n",
    "            'gb': GradientBoostingClassifier()\n",
    "        }\n",
    "        # 初始化投票分类器\n",
    "        self.voting_classifier = VotingClassifier(\n",
    "            estimators=[(name, model) for name, model in self.models.items()],\n",
    "            voting='hard'\n",
    "        )\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # 训练每个独立的机器学习模型\n",
    "        for model in self.models.values():\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        # 训练投票分类器\n",
    "        self.voting_classifier.fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # 使用投票分类器进行预测\n",
    "        return self.voting_classifier.predict(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # 评估投票分类器的准确率\n",
    "        return accuracy_score(y, self.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7988\n"
     ]
    }
   ],
   "source": [
    "# 创建集成模型的实例\n",
    "ensemble_model = MachineLearningEnsemble()\n",
    "\n",
    "# 训练集成模型\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上评估集成模型的性能\n",
    "val_accuracy = ensemble_model.score(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd Validation Accuracy: 0.7938\n",
      "pa Validation Accuracy: 0.7535\n",
      "svc Validation Accuracy: 0.8002\n",
      "ridge Validation Accuracy: 0.7919\n",
      "gb Validation Accuracy: 0.6655\n"
     ]
    }
   ],
   "source": [
    "# 如果你想评估每个单独模型的性能\n",
    "for name, model in ensemble_model.models.items():\n",
    "    model_accuracy = model.score(X_val, y_val)\n",
    "    print(f\"{name} Validation Accuracy: {model_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8008\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上评估集成模型的性能\n",
    "test_accuracy = ensemble_model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ensemble_model.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# 保存模型\n",
    "dump(ensemble_model, 'ensemble_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
